---
title: "Suicide Rates Overview 1985-2016"
author: "Khalil Hijazi"
date: "5/21/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

How commmon is suicide nowadays in comparison to a few decades ago? Which age and gender groups is suicide more prevalent? What factors prove to be leading causes of suicide? More importantly, how can we use this information to better prevent this problem? Using this [Kaggle Dataset](https://www.kaggle.com/russellyates88/suicide-rates-overview-1985-to-2016 "Suicide Rates Overview 1985 to 2016") as well as general principles of data science, we can appropriately address these questions and many more. First, I will demonstrate how to collect the data and put it into a machine-readable form. Next, I will show you how to process the data and do some exploratory analysis and visualization in order to come up with hypotheses about the data. Finally, I will show you how to test these hypotheses using machine learning.

## Required Tools

I will be using R 3.6.0 to carry out this analysis. Aside from that, here is a list of the libraries I'll be using:

* [tidyverse](https://www.tidyverse.org/ "Tidyverse")
* [magrittr](https://magrittr.tidyverse.org/ "magrittr")

Lastly, if you plan on following this guide, you will need to download the [Kaggle Dataset](https://www.kaggle.com/russellyates88/suicide-rates-overview-1985-to-2016 "Suicide Rates Overview 1985 to 2016"). **Note:** If you do not already have a Kaggle account, you will be required to create one to receive permission to download the dataset.

## 1. Getting Started

Let's first start by downloading the data. I downloaded the data as a CSV (comma separated values) file and stored it under the **data** subdirectory. 

Now, I will load the CSV file into a form that I can manipulate using R. To do so, I will use the **read_csv** function from the **tidyverse** package. It's important to note that R uses rectangular grid data structures for storing data called data frames. In a data frame, each row corresponds to an entity and each of the columns is an attribute for the entities across the table. That being said, the *read_csv* function takes the dataset CSV file and loads it into a data frame, which we can then easily work with in R. For more information on the **tidyverse** package and its features, feel free to check out this [resource](https://www.tidyverse.org/ "Tidyverse").

```{r load_data, message=FALSE}
library(tidyverse)
# loading data into data frame
file_path <- "data/master.csv"
suicide_data <- read_csv(file_path)
# printing first ten rows of data frame
suicide_data %>% slice(1:10)
```

### 1.1 Observing the Data

We now have a data frame called **suicide_data** that has all our data. Here, we can see the basic attributes our entities will share such as country, year, sex, age, and other factors related to each suicide instance. Any missing data is assigned a value of NA.

One last thing to note is that attributes can come in a variety of data types, but there are five main types (categorical, numeric, datetime, geolocation, and other). An attribute can only belong to one type (i.e. if it is categorical, it cannot be numeric unless represented otherwise). If it is a categorical attribute, then it must be either ordered or unordered. Categorically ordered attributes are ones that contain a fixed set of values that have some importance paradigm. Categorically unordered attributes on the other hand are the exact opposite in the sense that there is no significance to the values other than the fact that they are different values. Similarly, if an attribute is numerical, it can either be discrete or continuous. I won't go into depth of how this conclusion is arrived at but the general rule of thumb is that discrete numerical attributes are typically countable whereas continuous aren't.

Here are some examples from our dataset:

* 'country' | categorical unordered | Takes a value from a finite set of countries |
* 'suicides_no' | numeric discrete | Takes a value from a finite set of numeric integer suicide counts |
* 'suicides/100k pop' | numeric continuous | Takes a value from an infinite set of ratios of suicides to 100k populations |

### 1.2 Tidying the Data

Taking a look at the data, some modifications are needed for the purpose of our operations on that data. For instance, certain columns aren't necessary and can be deleted and more importantly, some attributes' datatypes need to be changed to other datatypes that are more suitable to the computations they'll be involved in.

I'll first start by removing the unnecessary columns. I'll be removing the 'country-year' attribute because that is simply a concatenation of the first two attributes and thus isn't necessary. I'll also be removing the 'HDI for year' attribute because there's just not much data on it. Lastly, I'll remove the 'generation' attribute because it is simply an encoding of the 'age' attribute, and thus we only need one of the two.

```{r remove_unnecessary_columns, comment=NA, message=F}
drops <- c("country-year", "HDI for year", "generation")
suicide_data[drops] <- NULL
suicide_data
```

Now that I've removed the unnecesssary columns, it's time to modify certain datatypes to our advantage. First, I'll change the 'year', 'suicides_no', 'population', and 'gdp_per_capita (\$)' attributes to integer columns instead of doubles. Although, the attribute 'gdp_for_year (\$)' is not a fractional number, I will leave it as a double because some of its entries are far too large to be represented as integer values in R.

**Note:** Here, I make use of the [magrittr](https://magrittr.tidyverse.org/ "magrittr") package. This package allows me to use the **%<>%** operation which is similar to the **%>%** dplyr operation, except that this one reassigns the data frame to whatever is resulted of the pipeline operations. So in this case, suicide_data is being modified once the columns have been mutated from doubles to integers.s

```{r modify_datatypes, comment+NA, message=F}
library(magrittr)
int_cols <- c('year', 'suicides_no', 'population', 'gdp_per_capita ($)')

suicide_data[int_cols] %<>%
  mutate_all(as.integer)

suicide_data
```

There are other methods of tidying data, such as uniting columns into one column or separating columns into multiple columns (we could've done this with the country-year column but it was easier to remove it since we already had two separate columns for country and year). Just because these methods weren't used, that doesn't mean they aren't important; it just means that they weren't needed for this dataset. As a data scientist, it is up to you to decide when certain methods are necessary and when not.